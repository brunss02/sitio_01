[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "sitio_01",
    "section": "",
    "text": "Este sitio surge de querer entender las relaciones entre las cadenas de Markov, los valores y vectores propios y el modelado de procesos sociales.\n\n\n\nUna de sus propiedades es que son memoryless, es decir, el pasado no influye en el resultado futuro, sino que únicamente intervine el presente.\nEn los modelos en cuestión el futuro se resume en el presente como un estado, el cual emerge con el paso del tiempo con cierta probabilidad\n\n\n\n\nUn modelo de Markov se especifica identificando:\n\na) los conjuntos de estados \\(S={1, ... , m}\\),\nb) el conjunto de transiciones posibles, es decir, los pares \\((i,j)\\) oara los cuales \\(p_{ij}&gt;0\\),\nc) los valores numéricos de estos \\(p_{ij}\\) son positivos\n\nLa cadena de Markov especificada por este modelo es una secuencia de variables aletorias \\(X_0, X_1, X_2,...,\\) que toma valores en \\(S\\), y que satisface\n\\[\n\\textbf{P}(X_{n+1} = j | X_n = i, X_{n-1}= i_{n-1}, ... ,X_0=i_0)=p_{ij},\n\\] para todo \\(n\\), todos los estados \\(i,j \\in S\\), y toda posible secuencia \\(i_0, ... , i_{n-1}\\) de estados previos.\nTodos los elementos de un modelo de cadena de Markov pueden codificarse en una matrix de probabilidades de transición, la cual es simplemente un arreglo bidimensional donde el elemento de la i-jésima fila y de la j-ésima columna es \\(p_{ij}\\):\n\\[\\begin{pmatrix}\np_{11} & p_{12} & p_{13} & \\cdots & p_{1n} \\\\\np_{21} & p_{22} & p_{23} & \\cdots & p_{2n} \\\\\np_{31} & p_{32} & p_{33} & \\cdots & p_{3n} \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\np_{n1} & p_{n2} & p_{n3} & \\cdots & p_{nn}\n\\end{pmatrix}\\]\ndonde \\(p_{ij}\\) representa la probabilidad de transición del estado \\(i\\) al estado \\(j\\).\n\n\n\nSupongamos que existen dos regiones habitables: N y S. Además, existe movilidad de personas entre las dos regiones y un estudio realizado ha revelado que las siguientes proporciones de personas se quedan en su región o que migran a la otra región en un periodo dado:\n\\[\\begin{pmatrix}\n0.5 & 0.25 \\\\\n0.5 & 0.75\n\\end{pmatrix}\\]\n\n\n\n\n\\(N_t\\) es la poblacion de la ciudad N en el momento t\n\\(S_t\\) es la poblacion de la ciudad S en el momento t\n\\(X_t = N_t + S_t\\)\n\\(\\textbf{x}_t =\\)\n\\[\\begin{pmatrix} n_t \\\\ s_t \\end{pmatrix}\\]\n\\(\\textbf{I} =\\)\n\\[\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\\]\nEl vector fila con la misma información es \\(\\textbf{I´}=\\begin{pmatrix} 1&1 \\end{pmatrix}\\). De forma que:\n\n\\[\n1=n_t +s_t= \\begin{pmatrix} 1&1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\textbf{I}´\\textbf{X}_t\n\\]\n\n\n\nRepresentemos la información que tenemos como un sistema de ecuaciones lineales: \\[\n\\begin{align}\nn_t = 0.5 n_{t-1} + 0.25 s_{t-1} \\\\\ns_t = 0.5 n_{t-1} + 0.75 s_{t-1}\n\\end{align}\n\\]"
  },
  {
    "objectID": "index.html#motivaciones",
    "href": "index.html#motivaciones",
    "title": "sitio_01",
    "section": "",
    "text": "Este sitio surge de querer entender las relaciones entre las cadenas de Markov, los valores y vectores propios y el modelado de procesos sociales."
  },
  {
    "objectID": "index.html#cadenas-de-markov",
    "href": "index.html#cadenas-de-markov",
    "title": "sitio_01",
    "section": "",
    "text": "Una de sus propiedades es que son memoryless, es decir, el pasado no influye en el resultado futuro, sino que únicamente intervine el presente.\nEn los modelos en cuestión el futuro se resume en el presente como un estado, el cual emerge con el paso del tiempo con cierta probabilidad"
  },
  {
    "objectID": "index.html#especificación-de-modelos-de-markov",
    "href": "index.html#especificación-de-modelos-de-markov",
    "title": "sitio_01",
    "section": "",
    "text": "Un modelo de Markov se especifica identificando:\n\na) los conjuntos de estados \\(S={1, ... , m}\\),\nb) el conjunto de transiciones posibles, es decir, los pares \\((i,j)\\) oara los cuales \\(p_{ij}&gt;0\\),\nc) los valores numéricos de estos \\(p_{ij}\\) son positivos\n\nLa cadena de Markov especificada por este modelo es una secuencia de variables aletorias \\(X_0, X_1, X_2,...,\\) que toma valores en \\(S\\), y que satisface\n\\[\n\\textbf{P}(X_{n+1} = j | X_n = i, X_{n-1}= i_{n-1}, ... ,X_0=i_0)=p_{ij},\n\\] para todo \\(n\\), todos los estados \\(i,j \\in S\\), y toda posible secuencia \\(i_0, ... , i_{n-1}\\) de estados previos.\nTodos los elementos de un modelo de cadena de Markov pueden codificarse en una matrix de probabilidades de transición, la cual es simplemente un arreglo bidimensional donde el elemento de la i-jésima fila y de la j-ésima columna es \\(p_{ij}\\):\n\\[\\begin{pmatrix}\np_{11} & p_{12} & p_{13} & \\cdots & p_{1n} \\\\\np_{21} & p_{22} & p_{23} & \\cdots & p_{2n} \\\\\np_{31} & p_{32} & p_{33} & \\cdots & p_{3n} \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\np_{n1} & p_{n2} & p_{n3} & \\cdots & p_{nn}\n\\end{pmatrix}\\]\ndonde \\(p_{ij}\\) representa la probabilidad de transición del estado \\(i\\) al estado \\(j\\).\n\n\n\nSupongamos que existen dos regiones habitables: N y S. Además, existe movilidad de personas entre las dos regiones y un estudio realizado ha revelado que las siguientes proporciones de personas se quedan en su región o que migran a la otra región en un periodo dado:\n\\[\\begin{pmatrix}\n0.5 & 0.25 \\\\\n0.5 & 0.75\n\\end{pmatrix}\\]\n\n\n\n\n\\(N_t\\) es la poblacion de la ciudad N en el momento t\n\\(S_t\\) es la poblacion de la ciudad S en el momento t\n\\(X_t = N_t + S_t\\)\n\\(\\textbf{x}_t =\\)\n\\[\\begin{pmatrix} n_t \\\\ s_t \\end{pmatrix}\\]\n\\(\\textbf{I} =\\)\n\\[\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\\]\nEl vector fila con la misma información es \\(\\textbf{I´}=\\begin{pmatrix} 1&1 \\end{pmatrix}\\). De forma que:\n\n\\[\n1=n_t +s_t= \\begin{pmatrix} 1&1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\textbf{I}´\\textbf{X}_t\n\\]\n\n\n\nRepresentemos la información que tenemos como un sistema de ecuaciones lineales: \\[\n\\begin{align}\nn_t = 0.5 n_{t-1} + 0.25 s_{t-1} \\\\\ns_t = 0.5 n_{t-1} + 0.75 s_{t-1}\n\\end{align}\n\\]"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Este sitio surge de querer entender las relaciones entre las cadenas de Markov, los valores y vectores propios y el modelado de procesos sociales.\n\n\n\nUna de sus propiedades es que son memoryless, es decir, el pasado no influye en el resultado futuro, sino que únicamente intervine el presente.\nEn los modelos en cuestión el futuro se resume en el presente como un estado, el cual emerge con el paso del tiempo con cierta probabilidad\nUna cadena de Markov discreta, donde se define como\n\\[                                                                                                                                \\]\n\n\n\n\nUn modelo de Markov se especifica identificando:\n\na) los conjuntos de estados \\(S={1, ... , m}\\),\nb) el conjunto de transiciones posibles, es decir, los pares \\((i,j)\\) oara los cuales \\(p_{ij}&gt;0\\),\nc) los valores numéricos de estos \\(p_{ij}\\) son positivos\n\nLa cadena de Markov especificada por este modelo es una secuencia de variables aletorias \\(X_0, X_1, X_2,...,\\) que toma valores en \\(S\\), y que satisface\n\\[\n\\textbf{P}(X_{n+1} = j | X_n = i, X_{n-1}= i_{n-1}, ... ,X_0=i_0)=p_{ij},\n\\] para todo \\(n\\), todos los estados \\(i,j \\in S\\), y toda posible secuencia \\(i_0, ... , i_{n-1}\\) de estados previos.\nTodos los elementos de un modelo de cadena de Markov pueden codificarse en una matrix de probabilidades de transición, la cual es simplemente un arreglo bidimensional donde el elemento de la i-jésima fila y de la j-ésima columna es \\(p_{ij}\\):\n\\[\\begin{pmatrix}\np_{11} & p_{12} & p_{13} & \\cdots & p_{1n} \\\\\np_{21} & p_{22} & p_{23} & \\cdots & p_{2n} \\\\\np_{31} & p_{32} & p_{33} & \\cdots & p_{3n} \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\np_{n1} & p_{n2} & p_{n3} & \\cdots & p_{nn}\n\\end{pmatrix}\\]\ndonde \\(p_{ij}\\) representa la probabilidad de transición del estado \\(i\\) al estado \\(j\\).\n\n\n\nSupongamos que existen dos regiones habitables: N y S. Además, existe movilidad de personas entre las dos regiones y un estudio realizado ha revelado que las siguientes proporciones de personas se quedan en su región o que migran a la otra región en un periodo dado:\n\\[\\begin{pmatrix}\n0.5 & 0.25 \\\\\n0.5 & 0.75\n\\end{pmatrix}\\]\n\n\n\n\n\\(N_t\\) es la poblacion de la ciudad N en el momento t\n\\(S_t\\) es la poblacion de la ciudad S en el momento t\n\\(X_t = N_t + S_t\\)\n\\(\\textbf{x}_t =\\)\n\\[\\begin{pmatrix} n_t \\\\ s_t \\end{pmatrix}\\]\n\\(\\textbf{I} =\\)\n\\[\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\\]\nEl vector fila con la misma información es \\(\\textbf{I´}=\\begin{pmatrix} 1&1 \\end{pmatrix}\\). De forma que:\n\n\\[\n1=n_t +s_t= \\begin{pmatrix} 1&1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\textbf{I}´\\textbf{X}_t\n\\] ### Metodología\nRepresentemos la información que tenemos como un sistema de ecuaciones lineales: \\[\n\\begin{align}\nn_t = 0.5 n_{t-1} + 0.25 s_{t-1} \\\\\ns_t = 0.5 n_{t-1} + 0.75 s_{t-1}\n\\end{align}\n\\]"
  },
  {
    "objectID": "about.html#motivaciones",
    "href": "about.html#motivaciones",
    "title": "About",
    "section": "",
    "text": "Este sitio surge de querer entender las relaciones entre las cadenas de Markov, los valores y vectores propios y el modelado de procesos sociales."
  },
  {
    "objectID": "about.html#cadenas-de-markov",
    "href": "about.html#cadenas-de-markov",
    "title": "About",
    "section": "",
    "text": "Una de sus propiedades es que son memoryless, es decir, el pasado no influye en el resultado futuro, sino que únicamente intervine el presente.\nEn los modelos en cuestión el futuro se resume en el presente como un estado, el cual emerge con el paso del tiempo con cierta probabilidad\nUna cadena de Markov discreta, donde se define como\n\\[                                                                                                                                \\]"
  },
  {
    "objectID": "about.html#especificación-de-modelos-de-markov",
    "href": "about.html#especificación-de-modelos-de-markov",
    "title": "About",
    "section": "",
    "text": "Un modelo de Markov se especifica identificando:\n\na) los conjuntos de estados \\(S={1, ... , m}\\),\nb) el conjunto de transiciones posibles, es decir, los pares \\((i,j)\\) oara los cuales \\(p_{ij}&gt;0\\),\nc) los valores numéricos de estos \\(p_{ij}\\) son positivos\n\nLa cadena de Markov especificada por este modelo es una secuencia de variables aletorias \\(X_0, X_1, X_2,...,\\) que toma valores en \\(S\\), y que satisface\n\\[\n\\textbf{P}(X_{n+1} = j | X_n = i, X_{n-1}= i_{n-1}, ... ,X_0=i_0)=p_{ij},\n\\] para todo \\(n\\), todos los estados \\(i,j \\in S\\), y toda posible secuencia \\(i_0, ... , i_{n-1}\\) de estados previos.\nTodos los elementos de un modelo de cadena de Markov pueden codificarse en una matrix de probabilidades de transición, la cual es simplemente un arreglo bidimensional donde el elemento de la i-jésima fila y de la j-ésima columna es \\(p_{ij}\\):\n\\[\\begin{pmatrix}\np_{11} & p_{12} & p_{13} & \\cdots & p_{1n} \\\\\np_{21} & p_{22} & p_{23} & \\cdots & p_{2n} \\\\\np_{31} & p_{32} & p_{33} & \\cdots & p_{3n} \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\np_{n1} & p_{n2} & p_{n3} & \\cdots & p_{nn}\n\\end{pmatrix}\\]\ndonde \\(p_{ij}\\) representa la probabilidad de transición del estado \\(i\\) al estado \\(j\\).\n\n\n\nSupongamos que existen dos regiones habitables: N y S. Además, existe movilidad de personas entre las dos regiones y un estudio realizado ha revelado que las siguientes proporciones de personas se quedan en su región o que migran a la otra región en un periodo dado:\n\\[\\begin{pmatrix}\n0.5 & 0.25 \\\\\n0.5 & 0.75\n\\end{pmatrix}\\]\n\n\n\n\n\\(N_t\\) es la poblacion de la ciudad N en el momento t\n\\(S_t\\) es la poblacion de la ciudad S en el momento t\n\\(X_t = N_t + S_t\\)\n\\(\\textbf{x}_t =\\)\n\\[\\begin{pmatrix} n_t \\\\ s_t \\end{pmatrix}\\]\n\\(\\textbf{I} =\\)\n\\[\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\\]\nEl vector fila con la misma información es \\(\\textbf{I´}=\\begin{pmatrix} 1&1 \\end{pmatrix}\\). De forma que:\n\n\\[\n1=n_t +s_t= \\begin{pmatrix} 1&1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\textbf{I}´\\textbf{X}_t\n\\] ### Metodología\nRepresentemos la información que tenemos como un sistema de ecuaciones lineales: \\[\n\\begin{align}\nn_t = 0.5 n_{t-1} + 0.25 s_{t-1} \\\\\ns_t = 0.5 n_{t-1} + 0.75 s_{t-1}\n\\end{align}\n\\]"
  }
]