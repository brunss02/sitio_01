[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "sitio_01",
    "section": "",
    "text": "Este sitio surge de querer entender las relaciones entre las cadenas de Markov, los valores y vectores propios y el modelado de procesos sociales.\n\n\n\nUna de sus propiedades es que son memoryless, es decir, el pasado no influye en el resultado futuro, sino que únicamente intervine el presente.\nEn los modelos en cuestión el futuro se resume en el presente como un estado, el cual emerge con el paso del tiempo con cierta probabilidad\nUna cadena de Markov discreta, donde se define como\n\\[                                \\]\n\n\n\n\nUn modelo de Markov se especifica identificando:\n\na) los conjuntos de estados \\(S={1, ... , m}\\),\nb) el conjunto de transiciones posibles, es decir, los pares \\((i,j)\\) oara los cuales \\(p_{ij}&gt;0\\),\nc) los valores numéricos de estos \\(p_{ij}\\) son positivos\n\nLa cadena de Markov especificada por este modelo es una secuencia de variables aletorias \\(X_0, X_1, X_2,...,\\) que toma valores en S, y que satisface\n\\[\n\\textbf{P}(X_{n+1} = j | X_n = i, X_{n-1}= i_{n-1}, ... ,X_0=i_0)=p_{ij},\n\\] para todo n, todos los estados \\(i,j \\in S\\), y toda posible secuencia \\(i_0, ... , i_{n-1}\\) de estados previos.\n\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html#motivaciones",
    "href": "index.html#motivaciones",
    "title": "sitio_01",
    "section": "",
    "text": "Este sitio surge de querer entender las relaciones entre las cadenas de Markov, los valores y vectores propios y el modelado de procesos sociales."
  },
  {
    "objectID": "index.html#cadenas-de-markov",
    "href": "index.html#cadenas-de-markov",
    "title": "sitio_01",
    "section": "",
    "text": "Una de sus propiedades es que son memoryless, es decir, el pasado no influye en el resultado futuro, sino que únicamente intervine el presente.\nEn los modelos en cuestión el futuro se resume en el presente como un estado, el cual emerge con el paso del tiempo con cierta probabilidad\nUna cadena de Markov discreta, donde se define como\n\\[                                \\]"
  },
  {
    "objectID": "index.html#especificación-de-modelos-de-markov",
    "href": "index.html#especificación-de-modelos-de-markov",
    "title": "sitio_01",
    "section": "",
    "text": "Un modelo de Markov se especifica identificando:\n\na) los conjuntos de estados \\(S={1, ... , m}\\),\nb) el conjunto de transiciones posibles, es decir, los pares \\((i,j)\\) oara los cuales \\(p_{ij}&gt;0\\),\nc) los valores numéricos de estos \\(p_{ij}\\) son positivos\n\nLa cadena de Markov especificada por este modelo es una secuencia de variables aletorias \\(X_0, X_1, X_2,...,\\) que toma valores en S, y que satisface\n\\[\n\\textbf{P}(X_{n+1} = j | X_n = i, X_{n-1}= i_{n-1}, ... ,X_0=i_0)=p_{ij},\n\\] para todo n, todos los estados \\(i,j \\in S\\), y toda posible secuencia \\(i_0, ... , i_{n-1}\\) de estados previos.\n\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  }
]